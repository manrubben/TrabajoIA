{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "\n",
    "titanic_dataset = 'docs/titanic.csv'\n",
    "breast_cancer_dataset = 'docs/breastCancerDataset.csv'\n",
    "\n",
    "titanic = pd.read_csv(titanic_dataset, header=0, delimiter=',', names=['Pclass', 'sex', 'age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Initial', \n",
    "'Age_band', 'Family_size', 'Alone', 'Fare_cat', 'Deck', 'Title', 'Is_Married', 'Survived']) # se lee el csv y \n",
    "                                                                                            #se indican el nombre de las columnas\n",
    "\n",
    "cancer = pd.read_csv(breast_cancer_dataset, header=0, delimiter=',', names=['mean radius', 'mean texture', 'mean perimeter', 'mean area', \n",
    "'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', \n",
    "'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', \n",
    "'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', \n",
    "'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension', 'diagnosis'])\n",
    "\n",
    "atributos_titanic = titanic.loc[:, 'Pclass':'Is_Married'] # selección de las columnas de atributos del dataset titanic\n",
    "objetivo_titanic = titanic['Survived'] # selección de la columna objetivo del dataset titanic\n",
    "\n",
    "atributos_cancer = cancer.loc[:, 'mean radius':'worst fractal dimension']\n",
    "objetivo_cancer = cancer['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_evaluacion_robusta(dataset, atributos, objetivo, N_EXP, CV):\n",
    "    \n",
    "    '''\n",
    "    Devuelve la media de las tasas de aciertos del algoritmo obtenidas en cada iteracion\n",
    "    '''\n",
    "\n",
    "    codificador_atributos = preprocessing.OrdinalEncoder() # Codificador adecuado para los atributos\n",
    "    codificador_atributos.fit(atributos)  # Ajusta la codificación a los atributos\n",
    "    atributos_codificados = codificador_atributos.transform(atributos)\n",
    "\n",
    "    codificador_objetivo = preprocessing.LabelEncoder() # Codificador adecuado para el objetivo\n",
    "    objetivo_codificado = codificador_objetivo.fit_transform(objetivo) # El método fit_transform ajusta la codificación y la aplica a los datos\n",
    "    \n",
    "    atributos_entrenamiento, atributos_prueba, objetivo_entrenamiento, objetivo_prueba = model_selection.train_test_split(\n",
    "    atributos_codificados, objetivo_codificado,  # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "    random_state=12345,  # Valor de la semilla aleatoria, para que el muestreo sea reproducible, a pesar de ser aleatorio\n",
    "    test_size=.20  # Tamaño del conjunto de prueba\n",
    "    )  \n",
    "\n",
    "    clasif_arbol_decision = tree.DecisionTreeClassifier() # creamos el clasificador\n",
    "    clasif_arbol_decision.fit(X=atributos_entrenamiento, y=objetivo_entrenamiento) \n",
    "    \n",
    "    lista_promedios = [] # Inicializamos una lista, en la que iremos metiendo los promedios\n",
    "\n",
    "    for i in range(N_EXP):\n",
    "        scores = model_selection.cross_val_score(estimator=clasif_arbol_decision, X=atributos_prueba, y=objetivo_prueba, cv=CV, scoring='balanced_accuracy')\n",
    "        # La variable scores almacena la tasa de aciertos del algoritmo sobre los datos que le pasamos como parámetros\n",
    "        promedio = scores.mean() # Calculamos el promedio como la media los scores\n",
    "        lista_promedios.append(promedio) #Añadimos el promedio a la lista de promedios\n",
    "    \n",
    "    media = sum(lista_promedios)/len(lista_promedios) # Calculamos la media de los promedios almacenados en la lista, que es \n",
    "                                                        # el dato que devolvera este método\n",
    "    return media\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8887500000000002"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metodo_evaluacion_robusta(cancer, atributos_cancer, objetivo_cancer, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoritmo_sfs(dataset, D):\n",
    "    \n",
    "    '''\n",
    "    Devuelve las K combinaciones de variables que proporcionan mayor rendimiento, acompañadas de su rendimiento y tamaño.\n",
    "    Todo esto mostrado en una tabla\n",
    "    '''\n",
    "    \n",
    "    solucion_actual = []    # Inicializamos la lista en la que almacenaremos la solucion actual\n",
    "    lista_auxiliar = []     # Inicializamos una lista auxiliar\n",
    "    solucion = []           # Esta lista se mostrara en la tabla. Contendra las mejores combinaciones de variables\n",
    "    lista_mejores_promedios = [] # Esta lista se mostrara en la tabla. Contendra los mejores promedios\n",
    "    size = []               # Esta lista se mostrara en la tabla. Contendra los K tamaños de la lista solucion\n",
    "    k=0                     # inicializamos K\n",
    "    variables_predictoras = dataset.columns.tolist() # Metemos en variables_predictoras los nombres de todas las columnas del dataset\n",
    "    nombre_objetivo = variables_predictoras.pop(len(variables_predictoras)-1) # Eliminamos de variables predictoras el nombre de la columna objetivo\n",
    "                                                                    # Y almacenamos en nombre_objetivo dicho nombre\n",
    "    objetivo = dataset[nombre_objetivo] # Obtenemos la columna objetivo del dataset\n",
    "    variables_sin_añadir = variables_predictoras # en variables sin añadir almacenamos los nombres de todas las \n",
    "                                                # columnas del dataset, exceptuando la del objetivo, eliminada anteriormente\n",
    "    i=1\n",
    "    while k < D:\n",
    "        lista_scores = [] #Inicializamos 3 listas mas, necesarias para que todos los datos se muestren en la tabla correctamente\n",
    "        lista_sol = []\n",
    "        solucion_auxiliar = []\n",
    "        for v in variables_sin_añadir: # recorremos las variables que aun no han sido añadidas\n",
    "            lista_sol = solucion_actual\n",
    "            lista_sol.append(dataset[v]) # Añadimos a lista_sol la columna del dataset cuyo nombre es la variable v\n",
    "            solucion_temporal = lista_sol # Pasamos a solucion_temporal la lista_sol\n",
    "            solucion_temporal = np.reshape(np.ravel(lista_sol), (len(objetivo),i+k)) # Transformamos el tamaño de la solucion \n",
    "                                                                 # temporal para que la solucion temporal tenga el mismo numero\n",
    "                                                                 # de filas que el objetivo\n",
    "            score = metodo_evaluacion_robusta(dataset, solucion_temporal, objetivo, 1, 3) # Calculamos el score\n",
    "            lista_scores.append(score) # Añadimos el score a la lista de scores\n",
    "            i=i+1 # Aumentamos i\n",
    "        mejor_promedio = np.amax(lista_scores) # Calculamos el mejor score de la lista de scores\n",
    "        mejor_solucion_temporal = variables_sin_añadir[lista_scores.index(mejor_promedio)] # La mejor solucion temporal sera la\n",
    "                                                                 # variable que haya obtenido el mejor promedio\n",
    "            \n",
    "        solucion_actual.append(dataset[mejor_solucion_temporal]) # Añadimos a solucion actual la columna del dataset cuyo nombre\n",
    "                                                                 # es la mejor solucion temporal\n",
    "        lista_auxiliar.append(mejor_solucion_temporal) # Añadimos dicha variable a una lista auxiliar\n",
    "        solucion_auxiliar = solucion_auxiliar + lista_auxiliar # Añadimos la lista auxiliar a otra lista para no tener problemas\n",
    "                                                               # a la hora de mostrar la tabla\n",
    "        solucion.append(solucion_auxiliar) # Añadimos a la lista solucion la lista solucion_auxiliar\n",
    "        lista_mejores_promedios.append(mejor_promedio) # Añadimos a la lista de mejores promedios el mejor promedio\n",
    "        size.append(len(solucion))   # Añadimos a la lista size el tamaño de la lista solucion\n",
    "        variables_sin_añadir.remove(variables_sin_añadir[lista_scores.index(mejor_promedio)]) # Borramos de variables_sin_añadir\n",
    "                                                                                              # la variable añadida\n",
    "        k=k+1 # Aumentamos K\n",
    "\n",
    "    print(\"\\nTabla respuesta:\\n\")\n",
    "    for j in range (0,D):\n",
    "        frame_data={'solution':solucion, 'score':lista_mejores_promedios, 'size':size}\n",
    "    df=pd.DataFrame(frame_data)\n",
    "\n",
    "    return df.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla respuesta:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution</th>\n",
       "      <th>score</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Pclass]</td>\n",
       "      <td>0.613810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Pclass, Family_size, Parch, Initial]</td>\n",
       "      <td>0.586071</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Pclass, Family_size]</td>\n",
       "      <td>0.573690</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Pclass, Family_size, Parch, Initial, Fare_cat]</td>\n",
       "      <td>0.557619</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Pclass, Family_size, Parch]</td>\n",
       "      <td>0.540754</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          solution     score  size\n",
       "0                                         [Pclass]  0.613810     1\n",
       "3            [Pclass, Family_size, Parch, Initial]  0.586071     4\n",
       "1                            [Pclass, Family_size]  0.573690     2\n",
       "4  [Pclass, Family_size, Parch, Initial, Fare_cat]  0.557619     5\n",
       "2                     [Pclass, Family_size, Parch]  0.540754     3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmo_sfs(titanic, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
